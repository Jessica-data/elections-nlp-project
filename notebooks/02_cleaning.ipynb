{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76aa8752",
   "metadata": {},
   "source": [
    "Context: This script constitutes the initial data preprocessing phase within the 02_cleaning.ipynb notebook. The primary objective is to transform raw election data into a structured format suitable for the subsequent predictive modeling of U.S. elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a803c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project Root: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project\n",
      "üìÇ Raw Data Dir: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/raw\n",
      "üìÇ Processed Data Dir: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed\n",
      "\n",
      "‚úÖ File successfully loaded.\n",
      "Detected columns: ['year', 'state', 'state_po', 'county_name', 'county_fips', 'office', 'candidate', 'party', 'candidatevotes', 'totalvotes', 'version', 'mode']\n",
      "Initial dataset shape: (94409, 12)\n",
      "Processing complete. Data saved to '/Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed/votes_cleaned_2000_2024.csv'\n",
      "\n",
      "First 5 rows of the cleaned dataset:\n",
      "   year state_po  county_name  county_fips  DEMOCRAT  REPUBLICAN\n",
      "0  2000       AK   DISTRICT 1       2001.0  0.192909    0.703275\n",
      "1  2000       AK  DISTRICT 10       2010.0  0.246961    0.638564\n",
      "2  2000       AK  DISTRICT 11       2011.0  0.292693    0.567335\n",
      "3  2000       AK  DISTRICT 12       2012.0  0.269833    0.608604\n",
      "4  2000       AK  DISTRICT 13       2013.0  0.335012    0.485081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURATION DES CHEMINS (PATH SETUP)\n",
    "# ==========================================\n",
    "# On d√©finit la racine du projet dynamiquement comme dans 01_data_collection\n",
    "current_dir = Path.cwd()\n",
    "PROJECT_ROOT = current_dir.parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# Cr√©ation du dossier processed s'il n'existe pas\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÇ Raw Data Dir: {RAW_DIR}\")\n",
    "print(f\"üìÇ Processed Data Dir: {PROCESSED_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: DATA LOADING (VOTES)\n",
    "# ==========================================\n",
    "# Utilisation du chemin dynamique\n",
    "file_path_votes = RAW_DIR / 'election_results' / 'countypres_2000-2024.csv'\n",
    "\n",
    "# V√©rification pour √©viter l'erreur FileNotFoundError\n",
    "if not file_path_votes.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Le fichier est introuvable ici : {file_path_votes}\")\n",
    "\n",
    "df_raw = pd.read_csv(file_path_votes, sep=None, engine='python')\n",
    "\n",
    "print(\"\\n‚úÖ File successfully loaded.\")\n",
    "print(f\"Detected columns: {df_raw.columns.tolist()}\")\n",
    "print(f\"Initial dataset shape: {df_raw.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: DATA CLEANING & FILTERING\n",
    "# ==========================================\n",
    "df_clean = df_raw[df_raw['party'].isin(['DEMOCRAT', 'REPUBLICAN'])].copy()\n",
    "df_clean['vote_share'] = df_clean['candidatevotes'] / df_clean['totalvotes']\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: DATA RESHAPING (PIVOTING)\n",
    "# ==========================================\n",
    "df_pivot = df_clean.pivot_table(\n",
    "    index=['year', 'state_po', 'county_name', 'county_fips'],\n",
    "    columns='party',\n",
    "    values='vote_share'\n",
    ").reset_index()\n",
    "\n",
    "df_pivot.columns.name = None\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: EXPORT & VALIDATION\n",
    "# ==========================================\n",
    "output_filename = \"votes_cleaned_2000_2024.csv\"\n",
    "save_path_votes = PROCESSED_DIR / output_filename\n",
    "\n",
    "df_pivot.to_csv(save_path_votes, index=False)\n",
    "\n",
    "print(f\"Processing complete. Data saved to '{save_path_votes}'\")\n",
    "print(\"\\nFirst 5 rows of the cleaned dataset:\")\n",
    "print(df_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be9378",
   "metadata": {},
   "source": [
    "We clean and filter the dataset in order to keep only the two major political parties (Democrats and Republicans). We calculate vote share to normalize the vote count. Then we transforme the dataset to from \"Observation per candidate\" to a \"county-year observation\". We impute missing values with 0 to account for counties where a specific party received no recorded votes. Finally, we export the clean dataset \"votes_cleaned_2000_2024.csv\" to /data/processed folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a569e",
   "metadata": {},
   "source": [
    "Context: This script processes the DP03_economic.csv file within the 02_cleaning.ipynb notebook. It focuses on preparing socio-economic predictors that will serve as independent variables in the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f337363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ File 'political_sentiment_DETAILED.csv' generated successfully!\n",
      "üìç Location: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed/political_sentiment_DETAILED.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/vt8p6nk92vx3gzt1_0rgwwth0000gn/T/ipykernel_7753/350573099.py:7: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,144,145,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,276,278,279,280,281,282,283,284,285,286,287,288,289,290,292,293,294,296,297,298,299,300,301,302,304,305,306,308,309,310,312,313,314,315,316,317,318,319,320,321,322,323,326,328,329,330,331,332,333,334,335,336,337,338,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,368,369,370,371,372,373,374,375,376,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,402,403,406,407,410,411,414,415,418,419,422,423,424,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,452,464,466,467,468,469,470,471,472,473,474,476,477,478,480,482,484,485,486,487,488,489,490,491,492,502,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,524,525,526,527,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_eco = pd.read_csv(file_path_eco, header=0)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 1: LOAD DATA (ECONOMICS)\n",
    "# ==========================================\n",
    "# Chemin dynamique vers le dossier socio-economic\n",
    "file_path_eco = RAW_DIR / 'socio-economic' / 'DP03_economic.csv'\n",
    "\n",
    "df_eco = pd.read_csv(file_path_eco, header=0)\n",
    "df_eco = df_eco.iloc[1:] # Remove description row\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: VARIABLE SELECTION\n",
    "# ==========================================\n",
    "columns_mapping = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'NAME': 'county_name',\n",
    "    'DP03_0009PE': 'unemployment_rate',\n",
    "    'DP03_0062E': 'median_income',\n",
    "    'DP03_0128PE': 'poverty_rate',\n",
    "    'DP03_0043PE': 'public_workers_pct'\n",
    "}\n",
    "\n",
    "df_eco_clean = df_eco[columns_mapping.keys()].rename(columns=columns_mapping).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: DATA CLEANING\n",
    "# ==========================================\n",
    "cols_to_convert = ['unemployment_rate', 'median_income', 'poverty_rate', 'public_workers_pct']\n",
    "for col in cols_to_convert:\n",
    "    df_eco_clean[col] = pd.to_numeric(df_eco_clean[col], errors='coerce')\n",
    "\n",
    "# Standardize FIPS (last 5 digits)\n",
    "df_eco_clean['fips'] = df_eco_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: EXPORT PROCESSED DATA\n",
    "# ==========================================\n",
    "output_name_eco = 'political_sentiment_DETAILED.csv'\n",
    "save_path_sentiment = PROCESSED_DIR / output_name_eco\n",
    "\n",
    "df_eco_clean.to_csv(save_path_sentiment, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ File '{output_name_eco}' generated successfully!\")\n",
    "print(f\"üìç Location: {save_path_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f49c4",
   "metadata": {},
   "source": [
    "Our DP03_economic represents our economic variables over the studied period. Since this dataset contains many variables, we firstly decide to keep a subset of relevant variables (FIPS number of the county, county name, unemployment rate, median income, poverty rate, public workers). We therefore create a new dataframe containing only the selected variables. Our next step was to convert economic factors from object/strings into numeric format to facilitate the later analysis. We then needed to extract the five last digits of the FIPS code to ensure that the matching can be done with our other datsets which have a \"5 digits\" FIPS code. We finish by exporting the clean dataset into our /data/processed folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37bed3",
   "metadata": {},
   "source": [
    "Context: This script processes the DP02_socio.csv file within the 02_cleaning.ipynb notebook. It isolates specific social demographic indicators‚Äîspecifically educational attainment‚Äîfor use in the predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9644c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Data Loaded. Dimensions: (3222, 619)\n",
      "Process Complete. File saved: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed/education_cleaned_2023.csv\n",
      "    fips  education_bachelors_pct\n",
      "1  01001                     28.3\n",
      "2  01003                     32.8\n",
      "3  01005                     11.5\n",
      "4  01007                     11.5\n",
      "5  01009                     15.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/vt8p6nk92vx3gzt1_0rgwwth0000gn/T/ipykernel_7753/1164140728.py:6: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,344,346,347,348,349,350,351,352,353,354,355,356,357,358,360,361,362,363,364,365,366,367,368,369,370,372,373,374,375,376,377,378,379,380,381,382,384,385,396,398,399,400,401,402,403,404,405,406,407,408,414,416,417,418,419,420,421,422,423,424,425,426,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,448,449,450,452,453,454,456,457,458,460,461,462,464,465,466,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,486,487,488,489,490,491,492,493,494,495,496,497,498,504,506,508,509,510,511,512,518,532,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,614,615,616,617) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_socio = pd.read_csv(file_path_socio, header=0)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 1: LOAD SOCIAL DATA (DP02)\n",
    "# ==========================================\n",
    "file_path_socio = RAW_DIR / 'socio-economic' / 'DP02_socio.csv'\n",
    "\n",
    "df_socio = pd.read_csv(file_path_socio, header=0)\n",
    "df_socio = df_socio.iloc[1:]\n",
    "\n",
    "print(f\"Social Data Loaded. Dimensions: {df_socio.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: VARIABLE SELECTION (EDUCATION)\n",
    "# ==========================================\n",
    "columns_mapping_socio = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'DP02_0068PE': 'education_bachelors_pct'\n",
    "}\n",
    "\n",
    "df_socio_clean = df_socio[columns_mapping_socio.keys()].rename(columns=columns_mapping_socio).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CLEANING\n",
    "# ==========================================\n",
    "df_socio_clean['education_bachelors_pct'] = pd.to_numeric(df_socio_clean['education_bachelors_pct'], errors='coerce')\n",
    "df_socio_clean['fips'] = df_socio_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: EXPORT\n",
    "# ==========================================\n",
    "output_filename_socio = \"education_cleaned_2023.csv\"\n",
    "save_path_edu = PROCESSED_DIR / output_filename_socio\n",
    "\n",
    "df_socio_clean.to_csv(save_path_edu, index=False)\n",
    "\n",
    "print(f\"Process Complete. File saved: {save_path_edu}\")\n",
    "print(df_socio_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef349f9c",
   "metadata": {},
   "source": [
    "Our DP02_socio represents our social variables over the studied period. Since this dataset contains many variables, we firstly decide to strictly focus on education (represents the percentage of the population aged 25 years and over who hold a Bachelor's degree or higher) . Our next step was to convert that variable from object/strings into numeric format to facilitate the later analysis. We then needed to extract the five last digits of the FIPS code to ensure that the matching can be done with our other datsets which have a \"5 digits\" FIPS code. We finish by exporting the clean dataset into our /data/processed folder. \n",
    "As an example, we can see that in county 01001, 28.3% of the population aged 25 years and over hold a Bachelor's degree or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e0e08",
   "metadata": {},
   "source": [
    "Context: This script processes the DP05_demo.csv file within the 02_cleaning.ipynb notebook. It is dedicated to preparing demographic features, specifically age and ethnicity, which are critical components of the socio-economic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc45141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Data Loaded. Dimensions: (3222, 379)\n",
      "Processing Complete. File saved: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed/demographics_cleaned_2023.csv\n",
      "    fips  median_age  white_pct  black_pct  hispanic_pct\n",
      "1  01001        39.2       73.6       20.0           0.8\n",
      "2  01003        43.7       82.8        8.0           1.6\n",
      "3  01005        40.7       44.0       46.9           0.9\n",
      "4  01007        41.3       75.1       20.7           1.9\n",
      "5  01009        40.9       89.5        1.3           1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/vt8p6nk92vx3gzt1_0rgwwth0000gn/T/ipykernel_7753/1843441251.py:6: DtypeWarning: Columns (2,4,6,8,10,12,13,14,15,16,18,20,22,24,26,27,28,29,30,32,33,34,35,36,37,38,40,41,42,44,45,46,47,48,50,52,54,56,58,60,62,66,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,138,139,140,141,142,143,144,145,146,147,148,149,150,152,154,155,156,157,158,159,160,161,162,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,192,194,198,200,201,202,203,204,206,208,210,212,214,215,216,217,218,220,221,222,223,226,228,229,230,232,233,234,235,236,238,240,242,246,248,250,254,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,326,327,328,329,330,331,332,333,334,335,336,337,338,340,342,343,344,345,346,347,348,349,350,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,372,374,375,376,377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_demo = pd.read_csv(file_path_demo, header=0)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 1: LOAD DEMOGRAPHIC DATA (DP05)\n",
    "# ==========================================\n",
    "file_path_demo = RAW_DIR / 'socio-economic' / 'DP05_demo.csv'\n",
    "\n",
    "df_demo = pd.read_csv(file_path_demo, header=0)\n",
    "df_demo = df_demo.iloc[1:]\n",
    "\n",
    "print(f\"Demographic Data Loaded. Dimensions: {df_demo.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: VARIABLE SELECTION\n",
    "# ==========================================\n",
    "columns_mapping_demo = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'DP05_0018E': 'median_age',\n",
    "    'DP05_0037PE': 'white_pct',\n",
    "    'DP05_0038PE': 'black_pct',\n",
    "    'DP05_0071PE': 'hispanic_pct'\n",
    "}\n",
    "\n",
    "df_demo_clean = df_demo[columns_mapping_demo.keys()].rename(columns=columns_mapping_demo).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CLEANING\n",
    "# ==========================================\n",
    "cols_to_convert = ['median_age', 'white_pct', 'black_pct', 'hispanic_pct']\n",
    "for col in cols_to_convert:\n",
    "    df_demo_clean[col] = pd.to_numeric(df_demo_clean[col], errors='coerce')\n",
    "\n",
    "df_demo_clean['fips'] = df_demo_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: EXPORT\n",
    "# ==========================================\n",
    "output_filename_demo = \"demographics_cleaned_2023.csv\"\n",
    "save_path_demo = PROCESSED_DIR / output_filename_demo\n",
    "\n",
    "df_demo_clean.to_csv(save_path_demo, index=False)\n",
    "\n",
    "print(f\"Processing Complete. File saved: {save_path_demo}\")\n",
    "print(df_demo_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979e5ba",
   "metadata": {},
   "source": [
    "Our DP05_demo represents our demographic variables over the studied period. Since this dataset contains many variables, we firstly decide to select relevent variables: Median Age spectrum positioning, Percentage White population, Percentage Black population (Black or African American alone), Percentage Hispanic population (Hispanic or Latino). Our next step was to convert those variable from object/strings into numeric format to facilitate the later analysis. We then needed to extract the five last digits of the FIPS code to ensure that the matching can be done with our other datsets which have a \"5 digits\" FIPS code. We finish by exporting the clean dataset into our /data/processed folder. \n",
    "As an example, we can see that in county 01001, 39.2% of the population has an age that correlates with the political spectrum positioning, 73,6% of the population is white, 20% is black and 0,8% is hispanic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e701998",
   "metadata": {},
   "source": [
    "Context: This script represents the culmination of the data preprocessing pipeline in 02_cleaning.ipynb. Its purpose is to aggregate the disparate cleaned datasets‚Äîelection results, economic indicators, educational attainment, and demographic profiles‚Äîinto a single, cohesive Master Table suitable for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd674096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standardizing FIPS codes... ---\n",
      "‚úÖ Validation: Votes FIPS Example : '02001'\n",
      "‚úÖ Validation: Eco FIPS Example   : '01001'\n",
      "\n",
      "Merging datasets...\n",
      "üéâ SAVED! The master file has been populated here: /Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/processed/master_table_elections.csv\n",
      "   year state_po  county_name   fips  DEMOCRAT  REPUBLICAN  unemployment_rate  \\\n",
      "0  2000       AK  DISTRICT 13  02013  0.335012    0.485081                3.8   \n",
      "1  2000       AK  DISTRICT 16  02016  0.420277    0.422625                4.1   \n",
      "2  2000       AK  DISTRICT 20  02020  0.324429    0.523912                4.6   \n",
      "3  2000       AL      AUTAUGA  01001  0.287192    0.696943                2.5   \n",
      "4  2000       AL      BALDWIN  01003  0.247822    0.723654                3.2   \n",
      "\n",
      "   median_income  poverty_rate  public_workers_pct  education_bachelors_pct  \\\n",
      "0        72692.0          12.4                 1.9                     18.1   \n",
      "1       107344.0           9.2                 4.4                     17.5   \n",
      "2        98152.0           9.3                 9.5                     37.7   \n",
      "3        69841.0          10.7                10.1                     28.3   \n",
      "4        75019.0          10.5                10.1                     32.8   \n",
      "\n",
      "   median_age  white_pct  black_pct  hispanic_pct  \n",
      "0        41.8       16.6        6.0          43.8  \n",
      "1        39.1       24.6        5.3          11.4  \n",
      "2        34.9       58.3        5.3          13.4  \n",
      "3        39.2       73.6       20.0           0.8  \n",
      "4        43.7       82.8        8.0           1.6  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 1: LOAD PROCESSED DATA\n",
    "# ==========================================\n",
    "# On red√©finit les chemins d'entr√©e bas√©s sur PROCESSED_DIR pour √™tre s√ªr\n",
    "path_votes_clean = PROCESSED_DIR / \"votes_cleaned_2000_2024.csv\"\n",
    "path_eco_clean   = PROCESSED_DIR / \"political_sentiment_DETAILED.csv\"\n",
    "path_edu_clean   = PROCESSED_DIR / \"education_cleaned_2023.csv\"\n",
    "path_demo_clean  = PROCESSED_DIR / \"demographics_cleaned_2023.csv\"\n",
    "\n",
    "# Chargement\n",
    "df_votes = pd.read_csv(path_votes_clean)\n",
    "df_eco   = pd.read_csv(path_eco_clean)\n",
    "df_edu   = pd.read_csv(path_edu_clean)\n",
    "df_demo  = pd.read_csv(path_demo_clean)\n",
    "\n",
    "# Standardization: Rename key in votes\n",
    "df_votes = df_votes.rename(columns={'county_fips': 'fips'})\n",
    "\n",
    "# ==========================================\n",
    "# üö® STEP 1.5: FIPS STANDARDIZATION & CLEANING\n",
    "# ==========================================\n",
    "def clean_fips(df):\n",
    "    \"\"\"Standardizes FIPS to 5-digit string format.\"\"\"\n",
    "    df['fips'] = pd.to_numeric(df['fips'], errors='coerce')\n",
    "    df = df.dropna(subset=['fips'])\n",
    "    df['fips'] = df['fips'].astype(int)\n",
    "    df['fips'] = df['fips'].astype(str).str.zfill(5)\n",
    "    return df\n",
    "\n",
    "print(\"--- Standardizing FIPS codes... ---\")\n",
    "df_votes = clean_fips(df_votes)\n",
    "df_eco   = clean_fips(df_eco)\n",
    "df_edu   = clean_fips(df_edu)\n",
    "df_demo  = clean_fips(df_demo)\n",
    "\n",
    "print(f\"‚úÖ Validation: Votes FIPS Example : '{df_votes['fips'].iloc[0]}'\")\n",
    "print(f\"‚úÖ Validation: Eco FIPS Example   : '{df_eco['fips'].iloc[0]}'\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: DATA FUSION (MERGE)\n",
    "# ==========================================\n",
    "print(\"\\nMerging datasets...\")\n",
    "# Inner Join: Votes + Eco (Must have both)\n",
    "df_master = pd.merge(df_votes, df_eco, on='fips', how='inner') \n",
    "\n",
    "# Left Join: + Education + Demo (Keep observation even if data missing)\n",
    "df_master = pd.merge(df_master, df_edu, on='fips', how='left')\n",
    "df_master = pd.merge(df_master, df_demo, on='fips', how='left')\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: COLUMN CLEANING\n",
    "# ==========================================\n",
    "cols_to_drop = [c for c in df_master.columns if c.endswith('_y') or 'county_name_eco' in c]\n",
    "df_master = df_master.drop(columns=cols_to_drop)\n",
    "df_master.columns = df_master.columns.str.replace('_x', '')\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: FINAL EXPORT (Master Table)\n",
    "# ==========================================\n",
    "output_filename_master = \"master_table_elections.csv\"\n",
    "save_path_master = PROCESSED_DIR / output_filename_master\n",
    "\n",
    "if len(df_master) > 0:\n",
    "    df_master.to_csv(save_path_master, index=False)\n",
    "    print(f\"üéâ SAVED! The master file has been populated here: {save_path_master}\")\n",
    "    print(df_master.head())\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Dataset is empty. Deep investigation required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87a737",
   "metadata": {},
   "source": [
    "After having cleaned all of the individual dataset, it was time to merge all of those socio-demo-eco variables in a single dataset. This is the purpose of the code here above. We exported the merged dataset into our data/processed folder. This dataset is thus ready for ML analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
