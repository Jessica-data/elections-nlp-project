{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76aa8752",
   "metadata": {},
   "source": [
    "Cleaning the countypres_2000-2024 file \n",
    "1. nettoyage du 'bruit', on ne garde que Repliblicans & Democrates\n",
    "2. on cr√©e des % pour avoir le m√™me poids pour tous les √©tats (500 √† LA ce n'est aps la m√™me chose que 500 votes dans un village du texas)\n",
    "3. reshaping : format long --> format large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a803c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier charg√© !\n",
      "Colonnes trouv√©es : ['year', 'state', 'state_po', 'county_name', 'county_fips', 'office', 'candidate', 'party', 'candidatevotes', 'totalvotes', 'version', 'mode']\n",
      "Initial dataset shape: (94409, 12)\n",
      "‚úÖ Filtrage r√©ussi !\n",
      "Processing complete. Data saved to 'votes_cleaned_2000_2024.csv'\n",
      "\n",
      "First 5 rows of the cleaned dataset:\n",
      "   year state_po  county_name  county_fips  DEMOCRAT  REPUBLICAN\n",
      "0  2000       AK   DISTRICT 1       2001.0  0.192909    0.703275\n",
      "1  2000       AK  DISTRICT 10       2010.0  0.246961    0.638564\n",
      "2  2000       AK  DISTRICT 11       2011.0  0.292693    0.567335\n",
      "3  2000       AK  DISTRICT 12       2012.0  0.269833    0.608604\n",
      "4  2000       AK  DISTRICT 13       2013.0  0.335012    0.485081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ==========================================\n",
    "# Load the raw CSV file using the correct separator\n",
    "file_path = '/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/raw/election_results/countypres_2000-2024.csv'\n",
    "df_raw = pd.read_csv(file_path, sep=None, engine='python')\n",
    "\n",
    "print(\"‚úÖ Fichier charg√© !\")\n",
    "print(f\"Colonnes trouv√©es : {df_raw.columns.tolist()}\")\n",
    "\n",
    "# Display initial shape\n",
    "print(f\"Initial dataset shape: {df_raw.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: DATA CLEANING & FILTERING\n",
    "# ==========================================\n",
    "# We only want to analyze the two major parties: Democrat and Republican.\n",
    "# This filters out Green, Libertarian, and other minor parties.\n",
    "df_clean = df_raw[df_raw['party'].isin(['DEMOCRAT', 'REPUBLICAN'])].copy()\n",
    "print(\"‚úÖ Filtrage r√©ussi !\")\n",
    "\n",
    "# Calculate the 'vote_share': the percentage of total votes a candidate received.\n",
    "# Formula: Candidate Votes / Total Votes in the County\n",
    "df_clean['vote_share'] = df_clean['candidatevotes'] / df_clean['totalvotes']\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: RESHAPING (PIVOT)\n",
    "# ==========================================\n",
    "# Transform the data from \"Long Format\" (one row per candidate) \n",
    "# to \"Wide Format\" (one row per county per year).\n",
    "# We want separate columns for Democrat and Republican vote shares.\n",
    "df_pivot = df_clean.pivot_table(\n",
    "    index=['year', 'state_po', 'county_name', 'county_fips'], # Unique identifiers for a row\n",
    "    columns='party',                                          # Values to become new columns\n",
    "    values='vote_share'                                       # The metric to populate the cells\n",
    ").reset_index()\n",
    "\n",
    "# Clean up column names (remove the hierarchy created by pivot_table)\n",
    "df_pivot.columns.name = None\n",
    "\n",
    "# Fill NaN values with 0 (in case a party received 0 votes in a county)\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: EXPORT & VALIDATION\n",
    "# ==========================================\n",
    "# Save the processed file for the next steps (Modeling)\n",
    "output_filename = \"votes_cleaned_2000_2024.csv\"\n",
    "df_pivot.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Processing complete. Data saved to '{output_filename}'\")\n",
    "print(\"\\nFirst 5 rows of the cleaned dataset:\")\n",
    "print(df_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a569e",
   "metadata": {},
   "source": [
    "Cleaning file DP03_economic.csv : \n",
    "1. on ne garde que 4 variables pour √©viter l'Overfitting (ch√¥mage, pauvret√©, revenus, fonctionnaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f337363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated economic file with 4 variables!\n",
      "    fips              county_name  unemployment_rate  median_income  \\\n",
      "1  01001  Autauga County, Alabama                2.5        69841.0   \n",
      "2  01003  Baldwin County, Alabama                3.2        75019.0   \n",
      "3  01005  Barbour County, Alabama                5.7        44290.0   \n",
      "4  01007     Bibb County, Alabama               10.0        51215.0   \n",
      "5  01009   Blount County, Alabama                5.8        61096.0   \n",
      "\n",
      "   poverty_rate  public_workers_pct  \n",
      "1          10.7                10.1  \n",
      "2          10.5                10.1  \n",
      "3          21.9                 8.6  \n",
      "4          20.5                 3.4  \n",
      "5          14.1                 5.9  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/2bt1kt6d0xzb95k0cn4jftsr0000gn/T/ipykernel_18391/185637181.py:10: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,144,145,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,276,278,279,280,281,282,283,284,285,286,287,288,289,290,292,293,294,296,297,298,299,300,301,302,304,305,306,308,309,310,312,313,314,315,316,317,318,319,320,321,322,323,326,328,329,330,331,332,333,334,335,336,337,338,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,368,369,370,371,372,373,374,375,376,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,402,403,406,407,410,411,414,415,418,419,422,423,424,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,452,464,466,467,468,469,470,471,472,473,474,476,477,478,480,482,484,485,486,487,488,489,490,491,492,502,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,524,525,526,527,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_eco = pd.read_csv(file_path_eco, header=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ==========================================\n",
    "file_path_eco = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/raw/socio-economic/DP03_economic.csv\"\n",
    "\n",
    "# Load with header=1 to get the codes\n",
    "df_eco = pd.read_csv(file_path_eco, header=0)\n",
    "df_eco = df_eco.iloc[1:] # Drop description row\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: SELECT VARIABLES (CUSTOMIZED)\n",
    "# ==========================================\n",
    "# I added 'DP03_0043PE' which is \"Government workers\" (Percent)\n",
    "# You can add as many as you want here if you know the code!\n",
    "\n",
    "columns_mapping = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'NAME': 'county_name',\n",
    "    'DP03_0009PE': 'unemployment_rate',      # Ch√¥mage\n",
    "    'DP03_0062E': 'median_income',           # Revenu\n",
    "    'DP03_0128PE': 'poverty_rate',           # Pauvret√©\n",
    "    'DP03_0043PE': 'public_workers_pct'      # (BONUS) Fonctionnaires\n",
    "}\n",
    "\n",
    "# Keep and rename\n",
    "df_eco_clean = df_eco[columns_mapping.keys()].rename(columns=columns_mapping).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CLEANING & TYPES\n",
    "# ==========================================\n",
    "# Convert all value columns to numbers\n",
    "cols_to_convert = ['unemployment_rate', 'median_income', 'poverty_rate', 'public_workers_pct']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df_eco_clean[col] = pd.to_numeric(df_eco_clean[col], errors='coerce')\n",
    "\n",
    "# Clean FIPS (Keep last 5 digits)\n",
    "df_eco_clean['fips'] = df_eco_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: SAVE\n",
    "# ==========================================\n",
    "df_eco_clean.to_csv(\"economics_cleaned_2023.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Updated economic file with 4 variables!\")\n",
    "print(df_eco_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37bed3",
   "metadata": {},
   "source": [
    "Cleaning the DP02_socio.csv file :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9644c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Social Data Loaded! Shape: (3222, 619)\n",
      "üéâ Process Complete! File saved: education_cleaned_2023.csv\n",
      "    fips  education_bachelors_pct\n",
      "1  01001                     28.3\n",
      "2  01003                     32.8\n",
      "3  01005                     11.5\n",
      "4  01007                     11.5\n",
      "5  01009                     15.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/2bt1kt6d0xzb95k0cn4jftsr0000gn/T/ipykernel_18391/2107103794.py:9: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,344,346,347,348,349,350,351,352,353,354,355,356,357,358,360,361,362,363,364,365,366,367,368,369,370,372,373,374,375,376,377,378,379,380,381,382,384,385,396,398,399,400,401,402,403,404,405,406,407,408,414,416,417,418,419,420,421,422,423,424,425,426,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,448,449,450,452,453,454,456,457,458,460,461,462,464,465,466,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,486,487,488,489,490,491,492,493,494,495,496,497,498,504,506,508,509,510,511,512,518,532,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,614,615,616,617) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_socio = pd.read_csv(file_path_socio, header=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: LOAD SOCIAL DATA (DP02)\n",
    "# ==========================================\n",
    "# ‚ö†Ô∏è Update the path below with your own \"Copy Path\" for DP02\n",
    "file_path_socio = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/raw/socio-economic/DP02_socio.csv\"\n",
    "\n",
    "df_socio = pd.read_csv(file_path_socio, header=0)\n",
    "df_socio = df_socio.iloc[1:] # Drop description row\n",
    "\n",
    "print(f\"‚úÖ Social Data Loaded! Shape: {df_socio.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: SELECT EDUCATION DATA\n",
    "# ==========================================\n",
    "# Key Variable:\n",
    "# - DP02_0068PE: Percent of people (25+) with a Bachelor's degree or higher\n",
    "\n",
    "columns_mapping_socio = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'DP02_0068PE': 'education_bachelors_pct'\n",
    "}\n",
    "\n",
    "df_socio_clean = df_socio[columns_mapping_socio.keys()].rename(columns=columns_mapping_socio).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CLEANING\n",
    "# ==========================================\n",
    "# Convert to numbers\n",
    "df_socio_clean['education_bachelors_pct'] = pd.to_numeric(df_socio_clean['education_bachelors_pct'], errors='coerce')\n",
    "\n",
    "# Clean FIPS code (last 5 characters)\n",
    "df_socio_clean['fips'] = df_socio_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: SAVE\n",
    "# ==========================================\n",
    "output_filename_socio = \"education_cleaned_2023.csv\"\n",
    "df_socio_clean.to_csv(output_filename_socio, index=False)\n",
    "\n",
    "print(f\"üéâ Process Complete! File saved: {output_filename_socio}\")\n",
    "print(df_socio_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e0e08",
   "metadata": {},
   "source": [
    "Cleaning the file DP05_demo.csv :\n",
    "1. on garde la variable age \n",
    "2. on garde les variables relatives √† l'origine √©thnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc45141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier D√©mo charg√© ! Taille : (3222, 379)\n",
      "üéâ Termin√© ! Fichier sauvegard√© : demographics_cleaned_2023.csv\n",
      "    fips  median_age  white_pct  black_pct  hispanic_pct\n",
      "1  01001        39.2       73.6       20.0           0.8\n",
      "2  01003        43.7       82.8        8.0           1.6\n",
      "3  01005        40.7       44.0       46.9           0.9\n",
      "4  01007        41.3       75.1       20.7           1.9\n",
      "5  01009        40.9       89.5        1.3           1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/2bt1kt6d0xzb95k0cn4jftsr0000gn/T/ipykernel_18391/1783815027.py:9: DtypeWarning: Columns (2,4,6,8,10,12,13,14,15,16,18,20,22,24,26,27,28,29,30,32,33,34,35,36,37,38,40,41,42,44,45,46,47,48,50,52,54,56,58,60,62,66,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,138,139,140,141,142,143,144,145,146,147,148,149,150,152,154,155,156,157,158,159,160,161,162,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,192,194,198,200,201,202,203,204,206,208,210,212,214,215,216,217,218,220,221,222,223,226,228,229,230,232,233,234,235,236,238,240,242,246,248,250,254,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,326,327,328,329,330,331,332,333,334,335,336,337,338,340,342,343,344,345,346,347,348,349,350,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,372,374,375,376,377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_demo = pd.read_csv(file_path_demo, header=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: LOAD DEMOGRAPHIC DATA (DP05)\n",
    "# ==========================================\n",
    "# ‚ö†Ô∏è Remplacez le chemin par celui de votre VRAI fichier DP05 sur votre ordinateur\n",
    "file_path_demo = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/raw/socio-economic/DP05_demo.csv\"\n",
    "\n",
    "df_demo = pd.read_csv(file_path_demo, header=0)\n",
    "df_demo = df_demo.iloc[1:] # On enl√®ve la ligne de description\n",
    "\n",
    "print(f\"‚úÖ Fichier D√©mo charg√© ! Taille : {df_demo.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: SELECT VARIABLES\n",
    "# ==========================================\n",
    "# Voici les variables cl√©s pour la politique US :\n",
    "# - DP05_0018E : Age M√©dian (Les jeunes votent plus √† gauche, les √¢g√©s √† droite)\n",
    "# - DP05_0037PE : % Blancs (White alone)\n",
    "# - DP05_0038PE : % Noirs (Black or African American alone)\n",
    "# - DP05_0071PE : % Hispaniques (Hispanic or Latino)\n",
    "\n",
    "columns_mapping_demo = {\n",
    "    'GEO_ID': 'fips',\n",
    "    'DP05_0018E': 'median_age',\n",
    "    'DP05_0037PE': 'white_pct',\n",
    "    'DP05_0038PE': 'black_pct',\n",
    "    'DP05_0071PE': 'hispanic_pct'\n",
    "}\n",
    "\n",
    "# On s√©lectionne et renomme\n",
    "df_demo_clean = df_demo[columns_mapping_demo.keys()].rename(columns=columns_mapping_demo).copy()\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CLEANING\n",
    "# ==========================================\n",
    "# Conversion en nombres\n",
    "cols_to_convert = ['median_age', 'white_pct', 'black_pct', 'hispanic_pct']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df_demo_clean[col] = pd.to_numeric(df_demo_clean[col], errors='coerce')\n",
    "\n",
    "# Nettoyage du code FIPS (les 5 derniers chiffres)\n",
    "df_demo_clean['fips'] = df_demo_clean['fips'].astype(str).str[-5:]\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: SAVE\n",
    "# ==========================================\n",
    "output_filename_demo = \"demographics_cleaned_2023.csv\"\n",
    "df_demo_clean.to_csv(output_filename_demo, index=False)\n",
    "\n",
    "print(f\"üéâ Termin√© ! Fichier sauvegard√© : {output_filename_demo}\")\n",
    "print(df_demo_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e701998",
   "metadata": {},
   "source": [
    "Master table (Merge to obtain our structured database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd674096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Nettoyage des FIPS en cours ---\n",
      "‚úÖ Exemple FIPS Votes (Doit √™tre 01001) : '02001'\n",
      "‚úÖ Exemple FIPS Eco   (Doit √™tre 01001) : '01001'\n",
      "\n",
      "Fusion...\n",
      "\n",
      "üìä Taille finale de la Master Table : 21742 lignes.\n",
      "üéâ SAUVEGARD√â ! Le fichier est plein.\n",
      "   year state_po  county_name   fips  DEMOCRAT  REPUBLICAN  unemployment_rate  \\\n",
      "0  2000       AK  DISTRICT 13  02013  0.335012    0.485081                3.8   \n",
      "1  2000       AK  DISTRICT 16  02016  0.420277    0.422625                4.1   \n",
      "2  2000       AK  DISTRICT 20  02020  0.324429    0.523912                4.6   \n",
      "3  2000       AL      AUTAUGA  01001  0.287192    0.696943                2.5   \n",
      "4  2000       AL      BALDWIN  01003  0.247822    0.723654                3.2   \n",
      "\n",
      "   median_income  poverty_rate  public_workers_pct  education_bachelors_pct  \\\n",
      "0        72692.0          12.4                 1.9                     18.1   \n",
      "1       107344.0           9.2                 4.4                     17.5   \n",
      "2        98152.0           9.3                 9.5                     37.7   \n",
      "3        69841.0          10.7                10.1                     28.3   \n",
      "4        75019.0          10.5                10.1                     32.8   \n",
      "\n",
      "   median_age  white_pct  black_pct  hispanic_pct  \n",
      "0        41.8       16.6        6.0          43.8  \n",
      "1        39.1       24.6        5.3          11.4  \n",
      "2        34.9       58.3        5.3          13.4  \n",
      "3        39.2       73.6       20.0           0.8  \n",
      "4        43.7       82.8        8.0           1.6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: LOAD (Colle tes chemins ici)\n",
    "# ==========================================\n",
    "path_votes = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/votes_cleaned_2000_2024.csv\"\n",
    "path_eco = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/economics_cleaned_2023.csv\"\n",
    "path_edu = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/education_cleaned_2023.csv\"\n",
    "path_demo = \"/Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/demographics_cleaned_2023.csv\"\n",
    "\n",
    "# On charge tout\n",
    "df_votes = pd.read_csv(path_votes)\n",
    "df_eco = pd.read_csv(path_eco)\n",
    "df_edu = pd.read_csv(path_edu)\n",
    "df_demo = pd.read_csv(path_demo)\n",
    "\n",
    "# Standardisation du nom de colonne\n",
    "df_votes = df_votes.rename(columns={'county_fips': 'fips'})\n",
    "\n",
    "# ==========================================\n",
    "# üö® STEP 1.5: LA LESSIVEUSE √Ä FIPS (CRUCIAL)\n",
    "# ==========================================\n",
    "def clean_fips(df):\n",
    "    # 1. On force en num√©rique pour g√©rer les \"1001.0\"\n",
    "    df['fips'] = pd.to_numeric(df['fips'], errors='coerce')\n",
    "    # 2. On enl√®ve les lignes o√π le FIPS est vide/cass√©\n",
    "    df = df.dropna(subset=['fips'])\n",
    "    # 3. On transforme en Entier (int) pour tuer le \".0\" -> 1001\n",
    "    df['fips'] = df['fips'].astype(int)\n",
    "    # 4. On transforme en Texte et on ajoute les z√©ros -> \"01001\"\n",
    "    df['fips'] = df['fips'].astype(str).str.zfill(5)\n",
    "    return df\n",
    "\n",
    "print(\"--- Nettoyage des FIPS en cours ---\")\n",
    "df_votes = clean_fips(df_votes)\n",
    "df_eco   = clean_fips(df_eco)\n",
    "df_edu   = clean_fips(df_edu)\n",
    "df_demo  = clean_fips(df_demo)\n",
    "\n",
    "print(f\"‚úÖ Exemple FIPS Votes (Doit √™tre 01001) : '{df_votes['fips'].iloc[0]}'\")\n",
    "print(f\"‚úÖ Exemple FIPS Eco   (Doit √™tre 01001) : '{df_eco['fips'].iloc[0]}'\")\n",
    "\n",
    "# Si les deux affichent '01001' (sans .0), la suite marchera !\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: FUSION\n",
    "# ==========================================\n",
    "print(\"\\nFusion...\")\n",
    "df_master = pd.merge(df_votes, df_eco, on='fips', how='inner') # On tente 'inner' pour voir ce qui matche vraiment\n",
    "df_master = pd.merge(df_master, df_edu, on='fips', how='left')\n",
    "df_master = pd.merge(df_master, df_demo, on='fips', how='left')\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: NETTOYAGE COLONNES\n",
    "# ==========================================\n",
    "cols_to_drop = [c for c in df_master.columns if c.endswith('_y') or 'county_name_eco' in c]\n",
    "df_master = df_master.drop(columns=cols_to_drop)\n",
    "df_master.columns = df_master.columns.str.replace('_x', '')\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: R√âSULTAT\n",
    "# ==========================================\n",
    "print(f\"\\nüìä Taille finale de la Master Table : {len(df_master)} lignes.\")\n",
    "if len(df_master) > 0:\n",
    "    df_master.to_csv(\"master_table_elections.csv\", index=False)\n",
    "    print(\"üéâ SAUVEGARD√â ! Le fichier est plein.\")\n",
    "    print(df_master.head())\n",
    "else:\n",
    "    print(\"‚ùå TOUJOURS VIDE... Le probl√®me est plus profond.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
