{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cffee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## DEMOCRATS 2000\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_manifesto_final(input_path: str, output_path: str) -> None:\n",
    "    text = Path(input_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    # Normalisation de base\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = text.replace(\"\\f\", \"\\n\")\n",
    "\n",
    "    # 1. Supprimer les en-têtes de pages restants du type\n",
    "    # \"2000 Democratic National Platform — 2\"\n",
    "    text = re.sub(\n",
    "        r\"^\\s*2000 Democratic National Platform\\s*[—-]\\s*\\d+\\s*$\",\n",
    "        \"\",\n",
    "        text,\n",
    "        flags=re.MULTILINE,\n",
    "    )\n",
    "\n",
    "    # 2. Supprimer les lignes qui ne contiennent qu'un numéro de page\n",
    "    text = re.sub(r\"^\\s*\\d+\\s*$\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # 3. Reconstruction de paragraphes + transformation des titres\n",
    "    lines = text.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    buffer = []\n",
    "\n",
    "    def flush_buffer():\n",
    "        nonlocal buffer, new_lines\n",
    "        if buffer:\n",
    "            paragraph = \" \".join(buffer)\n",
    "            paragraph = re.sub(r\"\\s{2,}\", \" \", paragraph)\n",
    "            new_lines.append(paragraph.strip())\n",
    "            buffer = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Ligne vide => fin de paragraphe\n",
    "        if stripped == \"\":\n",
    "            flush_buffer()\n",
    "            if new_lines and new_lines[-1] != \"\":\n",
    "                new_lines.append(\"\")\n",
    "            continue\n",
    "\n",
    "        # Lignes full uppercase = titres → Title Case\n",
    "        if stripped.isupper():\n",
    "            flush_buffer()\n",
    "            # Exemple : \"PROTECTING AMERICAN CONSUMERS\" -> \"Protecting American Consumers\"\n",
    "            title = stripped.title()\n",
    "            new_lines.append(title)\n",
    "            continue\n",
    "\n",
    "        # Cas général : texte normal\n",
    "        buffer.append(stripped)\n",
    "\n",
    "    # Dernier paragraphe\n",
    "    flush_buffer()\n",
    "\n",
    "    # 4. Nettoyage final\n",
    "    text_clean = \"\\n\".join(new_lines)\n",
    "    text_clean = re.sub(r\"\\n{3,}\", \"\\n\\n\", text_clean).strip() + \"\\n\"\n",
    "\n",
    "    Path(output_path).write_text(text_clean, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_manifesto_final(\n",
    "        input_path=\"/Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/raw/manifestos/2000-Democrats.txt\",\n",
    "        output_path=\"/Users/xavierfoidart/Documents/M1/Data Management/Projet/elections-nlp-project/data/raw/manifestos/2000-Democrats_clean_final.txt\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### REPUBLICANS 2000\n",
    "import argparse\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# ---------- Heuristics ----------\n",
    "\n",
    "def remove_toc_heuristic(lines: List[str], max_scan_lines: int = 200) -> List[str]:\n",
    "    \"\"\"\n",
    "    Simple heuristic to remove a Table of Contents at the beginning of a document.\n",
    "\n",
    "    - Look for 'CONTENTS' or 'TABLE OF CONTENTS' in the first N lines.\n",
    "    - If found, drop lines from that point until the first 'normal' paragraph.\n",
    "\n",
    "    'Normal' paragraph = non-empty line with length > 40 and not ending with a page number.\n",
    "    \"\"\"\n",
    "    idx_toc = None\n",
    "    for i, line in enumerate(lines[:max_scan_lines]):\n",
    "        stripped = line.strip().lower()\n",
    "        if stripped in {\"contents\", \"table of contents\"}:\n",
    "            idx_toc = i\n",
    "            break\n",
    "\n",
    "    if idx_toc is None:\n",
    "        return lines  # No TOC detected\n",
    "\n",
    "    # Find the end of the TOC block\n",
    "    end_idx = None\n",
    "    for j in range(idx_toc + 1, min(len(lines), idx_toc + max_scan_lines)):\n",
    "        stripped = lines[j].strip()\n",
    "        if (\n",
    "            stripped\n",
    "            and len(stripped) > 40\n",
    "            and not re.search(r\"\\d+\\s*$\", stripped)  # avoid entries ending with page numbers\n",
    "        ):\n",
    "            end_idx = j\n",
    "            break\n",
    "\n",
    "    if end_idx is None:\n",
    "        # Failsafe: if we don't find a safe restart point, do nothing\n",
    "        return lines\n",
    "\n",
    "    # Keep everything before TOC and resume at first normal paragraph after TOC\n",
    "    return lines[:idx_toc] + lines[end_idx:]\n",
    "\n",
    "\n",
    "def is_noise(line: str) -> bool:\n",
    "    \"\"\"\n",
    "    Detect obvious OCR garbage / corrupted lines.\n",
    "\n",
    "    Strategy:\n",
    "    - Compute ratio of alphabetic characters to total characters.\n",
    "    - If < 0.5 and line is not short, we drop it.\n",
    "    \"\"\"\n",
    "    text = line.strip()\n",
    "    if not text:\n",
    "        return False\n",
    "\n",
    "    # Very short lines we keep (could be section numbers, etc.)\n",
    "    if len(text) <= 5:\n",
    "        return False\n",
    "\n",
    "    letters = sum(c.isalpha() for c in text)\n",
    "    ratio = letters / max(1, len(text))\n",
    "\n",
    "    # Threshold: < 0.5 = likely noisy\n",
    "    if ratio < 0.5:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_header_candidate(line: str) -> bool:\n",
    "    \"\"\"\n",
    "    Decide if a line is probably a section header.\n",
    "\n",
    "    Rules:\n",
    "    - FULL UPPERCASE shortish lines → header\n",
    "    - Title Case short-ish lines → header\n",
    "    - Lines starting with Roman numeral + '.' → header\n",
    "    - Lines starting with '|.' + text → header\n",
    "    \"\"\"\n",
    "    stripped = line.strip()\n",
    "    if not stripped:\n",
    "        return False\n",
    "\n",
    "    # Rule 1: full uppercase (e.g. \"PROSPERITY\", \"RETIREMENT SECURITY\")\n",
    "    if stripped.isupper() and len(stripped) <= 80:\n",
    "        return True\n",
    "\n",
    "    # Rule 2: Title Case and not too long (e.g. \"Old Truths For The New Economy\")\n",
    "    if stripped.istitle() and len(stripped.split()) <= 10:\n",
    "        return True\n",
    "\n",
    "    # Rule 3: starts with Roman numeral (I., II., III., IV., etc.)\n",
    "    if re.match(r\"^[IVXLC]+\\.\\s+\", stripped):\n",
    "        return True\n",
    "\n",
    "    # Rule 4: starts with \"|.\" or similar bullet + text\n",
    "    if re.match(r\"^\\|\\.\\s*[A-Za-z]\", stripped):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def normalize_header(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a header line:\n",
    "    - Strip leading bullets like '|.' or roman numerals like 'III.'\n",
    "    - Convert to Title Case\n",
    "    \"\"\"\n",
    "    stripped = line.strip()\n",
    "\n",
    "    # Remove leading roman numeral markers: \"III. \" -> \"\"\n",
    "    stripped = re.sub(r\"^[IVXLC]+\\.\\s+\", \"\", stripped)\n",
    "\n",
    "    # Remove leading bullet like \"|.\" or similar\n",
    "    stripped = re.sub(r\"^\\|\\.\\s*\", \"\", stripped)\n",
    "\n",
    "    # Title Case for consistency\n",
    "    return stripped.title()\n",
    "\n",
    "\n",
    "# ---------- Core cleaning ----------\n",
    "\n",
    "def clean_manifesto_text(text: str, remove_toc: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Clean a manifesto text:\n",
    "    - Normalize line endings + remove form feeds\n",
    "    - Optionally remove TOC\n",
    "    - Remove page headers/footers & pure numeric page lines\n",
    "    - Remove noisy OCR lines\n",
    "    - Rebuild paragraphs\n",
    "    - Detect & normalize headers\n",
    "    \"\"\"\n",
    "    # Normalize line endings and remove form feeds\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = text.replace(\"\\f\", \"\\n\")\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    if remove_toc:\n",
    "        lines = remove_toc_heuristic(lines)\n",
    "\n",
    "    cleaned_lines: List[str] = []\n",
    "\n",
    "    # Pattern for page header/footer like \"... — 4\" or \"... - 12\"\n",
    "    header_footer_pattern = re.compile(r\"^\\s*.*\\s[—-]\\s*\\d+\\s*$\")\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Drop pure numeric page numbers (e.g. \"12\")\n",
    "        if re.fullmatch(r\"\\d+\", stripped):\n",
    "            continue\n",
    "\n",
    "        # Drop typical header/footer lines\n",
    "        if header_footer_pattern.match(line):\n",
    "            continue\n",
    "\n",
    "        # Drop obvious OCR noise\n",
    "        if is_noise(line):\n",
    "            continue\n",
    "\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    # Rebuild paragraphs and treat headers separately\n",
    "    new_lines: List[str] = []\n",
    "    buffer: List[str] = []\n",
    "\n",
    "    def flush_buffer():\n",
    "        nonlocal buffer, new_lines\n",
    "        if buffer:\n",
    "            paragraph = \" \".join(buffer)\n",
    "            paragraph = re.sub(r\"\\s{2,}\", \" \", paragraph)\n",
    "            paragraph = paragraph.strip()\n",
    "            if paragraph:\n",
    "                new_lines.append(paragraph)\n",
    "            buffer = []\n",
    "\n",
    "    for line in cleaned_lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Blank line → paragraph separator\n",
    "        if stripped == \"\":\n",
    "            flush_buffer()\n",
    "            if new_lines and new_lines[-1] != \"\":\n",
    "                new_lines.append(\"\")  # keep exactly one blank line\n",
    "            continue\n",
    "\n",
    "        # Header candidate\n",
    "        if is_header_candidate(stripped):\n",
    "            flush_buffer()\n",
    "            header = normalize_header(stripped)\n",
    "            new_lines.append(header)\n",
    "            continue\n",
    "\n",
    "        # Normal text → accumulate\n",
    "        buffer.append(stripped)\n",
    "\n",
    "    # Flush last paragraph\n",
    "    flush_buffer()\n",
    "\n",
    "    # Collapse multiple blank lines\n",
    "    final_text = \"\\n\".join(new_lines)\n",
    "    final_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", final_text).strip() + \"\\n\"\n",
    "\n",
    "    return final_text\n",
    "\n",
    "\n",
    "def clean_manifesto_file(input_path: Path, output_path: Path, remove_toc: bool = True) -> None:\n",
    "    text = input_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    cleaned = clean_manifesto_text(text, remove_toc=remove_toc)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    output_path.write_text(cleaned, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def clean_manifesto_folder(input_dir: Path, output_dir: Path, remove_toc: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Clean all .txt files in input_dir and write cleaned versions to output_dir\n",
    "    with the same filenames.\n",
    "    \"\"\"\n",
    "    for path in input_dir.glob(\"*.txt\"):\n",
    "        rel_name = path.name\n",
    "        out_path = output_dir / rel_name\n",
    "        print(f\"Cleaning {path} -> {out_path}\")\n",
    "        clean_manifesto_file(path, out_path, remove_toc=remove_toc)\n",
    "\n",
    "\n",
    "# ---------- CLI ----------\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Clean manifesto text files for NLP.\")\n",
    "    parser.add_argument(\n",
    "        \"--input-file\",\n",
    "        type=str,\n",
    "        help=\"Path to a single raw manifesto .txt file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-file\",\n",
    "        type=str,\n",
    "        help=\"Output path for the cleaned single file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input-dir\",\n",
    "        type=str,\n",
    "        help=\"Directory containing raw manifesto .txt files.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-dir\",\n",
    "        type=str,\n",
    "        help=\"Directory to store cleaned manifesto files.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-toc\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Disable heuristic removal of table of contents.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    remove_toc = not args.no_toc\n",
    "\n",
    "    # Single-file mode\n",
    "    if args.input_file and args.output_file:\n",
    "        clean_manifesto_file(Path(args.input_file), Path(args.output_file), remove_toc=remove_toc)\n",
    "\n",
    "    # Batch mode\n",
    "    elif args.input_dir and args.output_dir:\n",
    "        clean_manifesto_folder(Path(args.input_dir), Path(args.output_dir), remove_toc=remove_toc)\n",
    "\n",
    "    else:\n",
    "        raise SystemExit(\n",
    "            \"Specify either:\\n\"\n",
    "            \"  --input-file and --output-file\\n\"\n",
    "            \"or\\n\"\n",
    "            \"  --input-dir and --output-dir\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
