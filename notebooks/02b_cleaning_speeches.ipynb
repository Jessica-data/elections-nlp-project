{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841740ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c4cff",
   "metadata": {},
   "source": [
    "Context: This script initializes the Natural Language Processing (NLP) workflow within the 02b_cleaning_speeches.ipynb notebook. Its primary objective is to construct a text corpus comprising the nomination acceptance speeches of Democratic and Republican presidential candidates from 2000 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fcf614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for: Harris (2024)...\n",
      "Retrieving data for: Trump (2024)...\n",
      "Retrieving data for: Biden (2020)...\n",
      "Retrieving data for: Trump (2020)...\n",
      "Retrieving data for: Clinton (2016)...\n",
      "Retrieving data for: Trump (2016)...\n",
      "Retrieving data for: Obama (2012)...\n",
      "Retrieving data for: Romney (2012)...\n",
      "Retrieving data for: Obama (2008)...\n",
      "Retrieving data for: McCaine (2008)...\n",
      "Retrieving data for: Kerry (2004)...\n",
      "Retrieving data for: Bush (2004)...\n",
      "Retrieving data for: Gore (2000)...\n",
      "Retrieving data for: Bush (2000)...\n",
      "Scraping complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>candidate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Harris</td>\n",
       "      <td>The Vice President: Good evening! [ Laughs. ] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Thank you very much. Thank you very, very much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Biden</td>\n",
       "      <td>Good evening. Ella Baker, a giant of the civil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Thank you very much. Thank you very much. Than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Thank you all very, very much! Thank you for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       party candidate  \\\n",
       "0  2024    Democrat    Harris   \n",
       "1  2024  Republican     Trump   \n",
       "2  2020    Democrat     Biden   \n",
       "3  2020  Republican     Trump   \n",
       "4  2016    Democrat   Clinton   \n",
       "\n",
       "                                                text  \n",
       "0  The Vice President: Good evening! [ Laughs. ] ...  \n",
       "1  Thank you very much. Thank you very, very much...  \n",
       "2  Good evening. Ella Baker, a giant of the civil...  \n",
       "3  Thank you very much. Thank you very much. Than...  \n",
       "4  Thank you all very, very much! Thank you for t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: INITIALIZATION OF SCRAPING TARGETS\n",
    "# ==========================================\n",
    "# Define a list of dictionaries containing metadata and target URLs for presidential nomination acceptance speeches.\n",
    "# Source: The American Presidency Project (UCSB).\n",
    "urls_to_scrape = [\n",
    "    {\"year\": 2024, \"party\": \"Democrat\", \"candidate\": \"Harris\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-democratic-presidential-nomination-chicago-illinois\"},\n",
    "    {\"year\": 2024, \"party\": \"Republican\", \"candidate\": \"Trump\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-republican-national-convention-milwaukee\"},\n",
    "    {\"year\": 2020, \"party\": \"Democrat\", \"candidate\": \"Biden\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-democratic-presidential-nomination-wilmington-delaware\"},\n",
    "    {\"year\": 2020, \"party\": \"Republican\", \"candidate\": \"Trump\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-republican-presidential-nomination-2\"},\n",
    "    {\"year\": 2016, \"party\": \"Democrat\", \"candidate\": \"Clinton\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-democratic-national-convention\"},\n",
    "    {\"year\": 2016, \"party\": \"Republican\", \"candidate\": \"Trump\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-republican-national-convention-cleveland\"},\n",
    "    {\"year\": 2012, \"party\": \"Democrat\", \"candidate\": \"Obama\", \"url\": \"https://www.presidency.ucsb.edu/documents/remarks-accepting-the-presidential-nomination-the-democratic-national-convention-charlotte\"},\n",
    "    {\"year\": 2012, \"party\": \"Republican\", \"candidate\": \"Romney\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-republican-national-convention-tampa\"},\n",
    "    {\"year\": 2008, \"party\": \"Democrat\", \"candidate\": \"Obama\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-democratic-national-convention-denver\"},\n",
    "    {\"year\": 2008, \"party\": \"Republican\", \"candidate\": \"McCaine\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-republican-national-convention-saint\"},\n",
    "    {\"year\": 2004, \"party\": \"Democrat\", \"candidate\": \"Kerry\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-democratic-national-convention-boston\"},\n",
    "    {\"year\": 2004, \"party\": \"Republican\", \"candidate\": \"Bush\", \"url\": \"https://www.presidency.ucsb.edu/documents/remarks-accepting-the-presidential-nomination-the-republican-national-convention-new-york\"},\n",
    "    {\"year\": 2000, \"party\": \"Democrat\", \"candidate\": \"Gore\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-democratic-national-convention-los\"},\n",
    "    {\"year\": 2000, \"party\": \"Republican\", \"candidate\": \"Bush\", \"url\": \"https://www.presidency.ucsb.edu/documents/address-accepting-the-presidential-nomination-the-republican-national-convention-0\"},\n",
    "]\n",
    "\n",
    "speech_data = []\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: WEB SCRAPING LOOP\n",
    "# ==========================================\n",
    "# Iterate through each candidate's URL to retrieve the raw HTML content.\n",
    "for item in urls_to_scrape:\n",
    "    print(f\"Retrieving data for: {item['candidate']} ({item['year']})...\")\n",
    "    \n",
    "    try:\n",
    "        # Send an HTTP GET request to the target URL.\n",
    "        response = requests.get(item['url'])\n",
    "        \n",
    "        # Validate the HTTP status code (200 OK) before proceeding.\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content using BeautifulSoup.\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # DOM Traversal: Locate the specific 'div' container holding the speech transcript.\n",
    "            # The class 'field-docs-content' is specific to the structure of The American Presidency Project website.\n",
    "            content_div = soup.find('div', class_='field-docs-content')\n",
    "            \n",
    "            if content_div:\n",
    "                # Text Extraction: Retrieve text content while stripping HTML tags and excess whitespace.\n",
    "                text = content_div.get_text(separator=' ', strip=True)\n",
    "                \n",
    "                # Append the structured data to the list.\n",
    "                speech_data.append({\n",
    "                    \"year\": item['year'],\n",
    "                    \"party\": item['party'],\n",
    "                    \"candidate\": item['candidate'],\n",
    "                    \"text\": text\n",
    "                })\n",
    "            else:\n",
    "                print(f\"ERROR: No text content found for {item['candidate']}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Broken link or server error for {item['candidate']}\")\n",
    "            \n",
    "        # Rate Limiting: Pause execution for 1 second to respect the server's request policies.\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Critical Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: DATAFRAME CREATION\n",
    "# ==========================================\n",
    "# Convert the list of dictionaries into a pandas DataFrame for analysis.\n",
    "df_speeches = pd.DataFrame(speech_data)\n",
    "\n",
    "# Validation: Display the first few rows to verify data integrity.\n",
    "print(\"Scraping complete.\")\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754857ad",
   "metadata": {},
   "source": [
    "Context: This segment of the 02b_cleaning_speeches.ipynb notebook implements the text preprocessing phase, which is fundamental to ensuring the validity of subsequent Natural Language Processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7551eda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW   : The Vice President: Good evening! [ Laughs. ] [ Applause. ] Audience: Kamala! Kamala! Kamala! The Vice President: California. [ Laughs. ] [ Applause. \n",
      "CLEAN : Good evening! Audience: Kamala! Kamala! Kamala! The Vice President: California. Good evening, everyone. Good evening. Good evening. Oh, my goodness. G\n",
      "\n",
      "‚úÖ File 'president_speeches_clean.csv' successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def super_cleaning(text):\n",
    "    \"\"\"\n",
    "    Performs rigorous text preprocessing to isolate the spoken content \n",
    "    from transcript metadata and non-verbal annotations.\n",
    "    \"\"\"\n",
    "    # 1. Remove non-verbal annotations enclosed in square brackets \n",
    "    # (e.g., [Applause], [Laughter]) using regex.\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # 2. Remove content enclosed in parentheses.\n",
    "    # This often includes editor notes or additional non-verbal cues.\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # 3. Remove speaker attribution prefixes if present at the start.\n",
    "    # Checks the first 50 characters for a colon (e.g., \"The Vice President: ...\").\n",
    "    if \":\" in text[:50]: \n",
    "        text = text.split(\":\", 1)[1]\n",
    "    \n",
    "    # 4. Whitespace Normalization:\n",
    "    # Replace newline characters with spaces to ensure continuity.\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Collapse multiple whitespace characters into a single space and trim leading/trailing spaces.\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the raw text column to generate a standardized dataset.\n",
    "df_speeches['clean_text'] = df_speeches['text'].apply(super_cleaning)\n",
    "\n",
    "# Validation: Compare a sample of the raw vs. cleaned text (first 150 characters).\n",
    "print(\"RAW   :\", df_speeches['text'].iloc[0][:150])\n",
    "print(\"CLEAN :\", df_speeches['clean_text'].iloc[0][:150])\n",
    "\n",
    "# Export the processed corpus to a CSV file for NLP analysis.\n",
    "df_speeches.to_csv(\"president_speeches_clean.csv\", index=False)\n",
    "print(\"\\n‚úÖ File 'president_speeches_clean.csv' successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d225c76",
   "metadata": {},
   "source": [
    "Context: This code block represents a refinement stage within 02b_cleaning_speeches.ipynb. Having identified that the initial cleaning pass left residual artifacts (such as \"Audience:\" or moderator interventions), this script applies a more rigorous cleaning protocol to the president_speeches_clean.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0323b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier charg√© depuis : /Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/president_speeches_clean.csv\n",
      "Dimensions : (14, 4)\n",
      "Cleaning process initiated...\n",
      "File 'president_speeches_clean.csv' successfully updated.\n",
      "üìç Saved to: /Users/jessicabourdouxhe/Desktop/Master 1/Data/Projet /elections-nlp-project/data/processed/president_speeches_clean.csv\n",
      "The dataset now contains only the cleaned text version.\n",
      "\n",
      "Preview (first 100 characters):\n",
      "Good evening! Kamala! Kamala! Kamala! California. Good evening, everyone. Good evening. Good evening\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "# ==========================================\n",
    "# STEP 1: LOAD INTERMEDIATE DATA\n",
    "# ==========================================\n",
    "\n",
    "# 1. Configuration des chemins\n",
    "current_dir = Path.cwd()\n",
    "PROJECT_ROOT = current_dir.parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# 2. D√©finir le chemin exact du fichier √† charger\n",
    "input_filename = \"president_speeches_clean.csv\"\n",
    "load_path = PROCESSED_DIR / input_filename\n",
    "\n",
    "# 3. Charger le dataset\n",
    "# On v√©rifie d'abord que le fichier existe pour √©viter le crash brutal\n",
    "if load_path.exists():\n",
    "    df = pd.read_csv(load_path)\n",
    "    print(f\"‚úÖ Fichier charg√© depuis : {load_path}\")\n",
    "    print(f\"Dimensions : {df.shape}\")\n",
    "else:\n",
    "    print(f\"‚ùå ERREUR : Le fichier est introuvable ici : {load_path}\")\n",
    "    print(\"Avez-vous bien ex√©cut√© l'√©tape d'export pr√©c√©dente ?\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: DEFINE ADVANCED CLEANING FUNCTION\n",
    "# ==========================================\n",
    "def ultimate_cleaning(text):\n",
    "    \"\"\"\n",
    "    Performs a secondary, granular cleaning pass to remove specific speaker \n",
    "    attributions and residual transcriptional artifacts.\n",
    "    \"\"\"\n",
    "    # Validation: Ensure the input is a string; otherwise return an empty string.\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    \n",
    "    # Remove content enclosed in brackets [] and parentheses ().\n",
    "    # This targets non-verbal annotations such as applause or laughter.\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # Remove specific speaker prefixes (e.g., \"Audience:\", \"The Vice President:\").\n",
    "    # This regex removes phrases resembling \"Title:\" at the beginning of a segment\n",
    "    # to ensure the text strictly reflects the candidate's speech.\n",
    "    text = re.sub(r'\\b(Audience|The Vice President|The President|Hon\\.|Mr\\.|Ms\\.|Mrs\\.)\\s*:', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize whitespace:\n",
    "    # Replace newlines with spaces and collapse multiple spaces into a single instance.\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: APPLY CLEANING\n",
    "# ==========================================\n",
    "print(\"Cleaning process initiated...\")\n",
    "df['clean_text'] = df['text'].apply(ultimate_cleaning)\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: FEATURE SELECTION\n",
    "# ==========================================\n",
    "# Select only the relevant metadata and the cleaned text column.\n",
    "# The raw text is discarded to optimize the dataset for NLP analysis.\n",
    "df_final = df[['year', 'party', 'candidate', 'clean_text']].copy()\n",
    "\n",
    "# Rename 'clean_text' to 'text' to standardize the column schema.\n",
    "df_final.rename(columns={'clean_text': 'text'}, inplace=True)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 5: SAVE FINAL DATASET (Speeches)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Configuration des chemins\n",
    "current_dir = Path.cwd()\n",
    "PROJECT_ROOT = current_dir.parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# 2. S√©curit√© : Cr√©ation du dossier s'il n'existe pas\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3. D√©finition du chemin complet\n",
    "output_filename = \"president_speeches_clean.csv\"\n",
    "save_path_speeches = PROCESSED_DIR / output_filename\n",
    "\n",
    "\n",
    "\n",
    "print(f\"File '{output_filename}' successfully updated.\")\n",
    "print(f\"üìç Saved to: {save_path_speeches}\")\n",
    "print(\"The dataset now contains only the cleaned text version.\")\n",
    "\n",
    "print(\"\\nPreview (first 100 characters):\")\n",
    "# J'ai gard√© votre slice [:100] qui est plus informative que 50\n",
    "print(df_final['text'].iloc[0][:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
